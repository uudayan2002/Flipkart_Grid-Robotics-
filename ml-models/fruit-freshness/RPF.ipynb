{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow model zoo downloader\n",
    "def load_model(model_name):    \n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "    model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In the Detection model file, there is a labelmap.pbtxt made for this project. Set the path to run this block\n",
    "PATH_TO_LABELS = r'C:\\Users\\LG\\Documents\\models\\research\\object_detection\\Images\\labelmap.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/LG/Desktop/images.jpg')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A path for your images to be tested from should be set here.\n",
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path(r'C:\\Users\\LG\\Desktop')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the pre-trained object_detection model for this project (Currrent loss:0.253)\n",
    "#The model is located in the Detection model file (select the path to saved_model.pb file)\n",
    "detection_model1 = tf.saved_model.load(r'C:\\Users\\LG\\Documents\\models\\research\\object_detection\\inference_graph1\\saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function performs detection on the image passed.\n",
    "def run_inference_for_single_image(model, image):\n",
    "    \n",
    "    image = np.asarray(image)\n",
    "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    \n",
    "  # Run inference\n",
    "    model_fn = model.signatures['serving_default']\n",
    "    output_dict = model_fn(input_tensor)\n",
    "\n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  # We're only interested in the first num_detections.\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "  # detection_classes should be ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "  # Handle models with masks:\n",
    "    if 'detection_masks' in output_dict:\n",
    "    # Reframe the the bbox mask to the image size.\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                       tf.uint8)\n",
    "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the Classification models file are the pre-trained models. set the path to run this block.\n",
    "import pickle\n",
    "import bz2\n",
    "import _pickle as cPickle\n",
    "\n",
    "# Load any compressed pickle file\n",
    "def decompress_pickle(file):\n",
    "    data = bz2.BZ2File(file, 'rb')\n",
    "    data = cPickle.load(data)\n",
    "    return data\n",
    "model  = decompress_pickle('orange.pbz2')\n",
    "model0 = decompress_pickle('banana.pbz2')\n",
    "model1 = decompress_pickle('pineapple.pbz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class is to set the properties for each of the detection boxes. the more the objects, the more the detection boxes can be found on image\n",
    "class Boxes():\n",
    "    \n",
    "    def __init__(self, i, image):\n",
    "        Categories = ['Ripe:', 'Unripe:']\n",
    "        self.image = image\n",
    "        shape = list(self.image.shape)\n",
    "        im_height = int(shape[0])\n",
    "        im_width =int(shape[1])\n",
    "        output_dict = run_inference_for_single_image(detection_model1, self.image)\n",
    "        self.ymin = int(output_dict['detection_boxes'][i][0]*im_height)\n",
    "        self.xmin = int(output_dict['detection_boxes'][i][1]*im_width)\n",
    "        self.ymax = int(output_dict['detection_boxes'][i][2]*im_height)\n",
    "        self.xmax = int(output_dict['detection_boxes'][i][3]*im_width)\n",
    "        self.roi = self.image[self.ymin:self.ymax,self.xmin:self.xmax]\n",
    "        self.label = str(output_dict['detection_classes'][i])\n",
    "        self.ripeness = '9'\n",
    "        self.colour = 3\n",
    "        \n",
    "#         if  (self.label == '1') or(self.label == '2') or (self.label == '4') :\n",
    "#             pass\n",
    "        #Orange\n",
    "        if (self.label == '3'):\n",
    "            sample = cv2.resize(self.roi, (100, 100))\n",
    "            sample = sample.flatten()\n",
    "            sample = np.array(sample).reshape(1,-1)\n",
    "            self.label = Categories[model.predict(sample)[0]]\n",
    "\n",
    "            if self.label == 'Ripe:':\n",
    "                \n",
    "                self.colour = (0,165,255)\n",
    "                self.ripeness = str(model.predict_proba(sample)[0][0]*100)[:2]+ '%'\n",
    "            else:\n",
    "                self.ripeness = str(model.predict_proba(sample)[0][1]*100)[:2]+ '%'\n",
    "                self.colour = (32,80,1)\n",
    "#         else:\n",
    "#              pass\n",
    "#         #Banana\n",
    "        if  (self.label == '1') or(self.label == '2') or (self.label == '4'):\n",
    "            sample = cv2.resize(self.roi, (100, 100))\n",
    "            sample = sample.flatten()\n",
    "            sample = np.array(sample).reshape(1,-1)\n",
    "            self.label = Categories[model0.predict(sample)[0]]\n",
    "\n",
    "\n",
    "            if self.label == 'Ripe:':\n",
    "                \n",
    "                self.colour = (0,255,255)\n",
    "                self.ripeness = str(model0.predict_proba(sample)[0][0]*100)[:2]+ '%'\n",
    "            else:\n",
    "                self.ripeness = str(model0.predict_proba(sample)[0][1]*100)[:2]+ '%'\n",
    "                self.colour = (0,255,0)\n",
    "#          Pineapple\n",
    "        if (self.label == '5'):\n",
    "            sample = cv2.resize(self.roi, (100, 100))\n",
    "            sample = sample.flatten()\n",
    "            sample = np.array(sample).reshape(1,-1)\n",
    "            self.label = Categories[model1.predict(sample)[0]]\n",
    "\n",
    "            if self.label == 'Ripe:':\n",
    "                \n",
    "                self.colour = (0,0,255)\n",
    "                self.ripeness = str(model1.predict_proba(sample)[0][0]*100)[:2]+ '%'\n",
    "            else:\n",
    "                self.ripeness = str(model1.predict_proba(sample)[0][1]*100)[:2]+ '%'\n",
    "                self.colour = (255,0,0)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Live Detection (WEBCAM NEEDED)\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "Categories = ['Ripe:', 'Unripe:']\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, image_np = cap.read()\n",
    "    # Actual detection.\n",
    "    output_dict= run_inference_for_single_image(detection_model1, image_np)\n",
    "    \n",
    "    #Detection_Boxes\n",
    "    box0 = Boxes(0, image_np)\n",
    "    box1 = Boxes(1, image_np)\n",
    "    box2 = Boxes(2, image_np)\n",
    "    \n",
    "    try:\n",
    "        if output_dict['detection_scores'][0]>= 0.5:\n",
    "\n",
    "            cv2.rectangle(image_np,(box0.xmin,box0.ymin),(box0.xmax,box0.ymax),box0.colour,2)\n",
    "            cv2.rectangle(image_np,(box0.xmin,box0.ymin-60),(box0.xmax,box0.ymin),box0.colour,-1)\n",
    "            cv2.putText(image_np, box0.label, (box0.xmin, box0.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "            cv2.putText(image_np, box0.ripeness, (box0.xmin, box0.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "        if output_dict['detection_scores'][1]>= 0.5:\n",
    "\n",
    "            cv2.rectangle(image_np,(box1.xmin,box1.ymin),(box1.xmax,box1.ymax),box1.colour,2)\n",
    "            cv2.rectangle(image_np,(box1.xmin,box1.ymin-60),(box1.xmax,box1.ymin),box1.colour,-1)\n",
    "            cv2.putText(image_np, box1.label, (box1.xmin, box1.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "            cv2.putText(image_np, box1.ripeness, (box1.xmin, box1.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "\n",
    "        if output_dict['detection_scores'][2]>= 0.5:\n",
    "\n",
    "            cv2.rectangle(image_np,(box2.xmin,box2.ymin),(box2.xmax,box2.ymax),box2.colour,2)\n",
    "            cv2.rectangle(image_np,(box2.xmin,box2.ymin-60),(box2.xmax,box2.ymin),box2.colour,-1)\n",
    "            cv2.putText(image_np, box2.label, (box2.xmin, box2.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "            cv2.putText(image_np, box2.ripeness, (box2.xmin, box2.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cv2.imshow('object detection', cv2.resize(image_np, (800,600),-1))\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Detection (set path to image, or pass name of image if image is in this directory)\n",
    "import cv2\n",
    "import numpy as np\n",
    "# image = \"download(1).jpg\"\n",
    "image = cv2.imread(\"images.jpg\")\n",
    "# image = cv2.resize(image, (800, 600))\n",
    "# shape = list(image.shape)\n",
    "# im_height = int(shape[0])\n",
    "# im_width =int(shape[1])\n",
    "    \n",
    "\n",
    "def RBF(detection_model, image):\n",
    "    \n",
    "    output_dict = run_inference_for_single_image(detection_model, image)\n",
    "    box0 = Boxes(0, image)\n",
    "    box1 = Boxes(1, image)\n",
    "    box2 = Boxes(2, image)\n",
    "    if (output_dict['detection_classes'][0]==3) & (output_dict['detection_scores'][0]>= 0.5):\n",
    "\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin),(box0.xmax,box0.ymax),box0.colour,2)\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin-60),(box0.xmax,box0.ymin),box0.colour,-1)\n",
    "        image = cv2.putText(image, box0.label, (box0.xmin, box0.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box0.ripeness, (box0.xmin, box0.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "    if (output_dict['detection_classes'][1]==3) & (output_dict['detection_scores'][1]>= 0.5):\n",
    "\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin),(box1.xmax,box1.ymax),box1.colour,2)\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin-60),(box1.xmax,box1.ymin),box1.colour,-1)\n",
    "        image = cv2.putText(image, box1.label, (box1.xmin, box1.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box1.ripeness, (box1.xmin, box1.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    #pineaple\n",
    "\n",
    "    if (output_dict['detection_classes'][0]==5) & (output_dict['detection_scores'][0]>= 0.5):\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin),(box0.xmax,box0.ymax),box0.colour,2)\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin-60),(box0.xmax,box0.ymin),box0.colour,-1)\n",
    "        image = cv2.putText(image, box0.label, (box0.xmin, box0.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box0.ripeness, (box0.xmin, box0.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "    if (output_dict['detection_classes'][1]==5) & (output_dict['detection_scores'][1]>= 0.5):\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin),(box1.xmax,box1.ymax),box1.colour,2)\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin-60),(box1.xmax,box1.ymin),box1.colour,-1)\n",
    "        image = cv2.putText(image, box1.label, (box1.xmin, box1.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box1.ripeness, (box1.xmin, box1.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    #banana\n",
    "#     if (output_dict['detection_classes'][1]==4) & (output_dict['detection_scores'][1]>= 0.5):\n",
    "    if (output_dict['detection_classes'][0]==2) & (output_dict['detection_scores'][0]>= 0.5):\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin),(box0.xmax,box0.ymax),box0.colour,2)\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin-60),(box0.xmax,box0.ymin),box0.colour,-1)\n",
    "        image = cv2.putText(image, box0.label, (box0.xmin, box0.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box0.ripeness, (box0.xmin, box0.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "    if (output_dict['detection_classes'][1]==2) & (output_dict['detection_scores'][1]>= 0.7):\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin),(box1.xmax,box1.ymax),box1.colour,2)\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin-60),(box1.xmax,box1.ymin),box1.colour,-1)\n",
    "        image = cv2.putText(image, box1.label, (box1.xmin, box1.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box1.ripeness, (box1.xmin, box1.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "#     image = cv2.resize(image, (800, 600))\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display\n",
    "cv2.imshow('image',RBF(detection_model1, image))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Detection for processing and filming\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('Unripe.mp4')\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter('unrapeban.mp4',cv2.VideoWriter_fourcc('X','V','I','D'), 30, (frame_width,frame_height))\n",
    "Categories = ['Ripe:', 'Unripe:']\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    # Actual detection.\n",
    "    try:\n",
    "        output_dict = run_inference_for_single_image(detection_model1, image)\n",
    "        # I set to best three boxes to be detected for this project. more can be created \n",
    "        box0 = Boxes(0, image)\n",
    "        box1 = Boxes(1, image)\n",
    "        box2 = Boxes(2, image)\n",
    "    except:\n",
    "        pass\n",
    "# first Box condition for three classes \n",
    "    if (output_dict['detection_classes'][0]==5) & (output_dict['detection_scores'][0]>= 0.4):\n",
    "\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin),(box0.xmax,box0.ymax),box0.colour,2)\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin-60),(box0.xmax,box0.ymin),box0.colour,-1)\n",
    "        image = cv2.putText(image, box0.label, (box0.xmin, box0.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box0.ripeness, (box0.xmin, box0.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "              \n",
    "    if  (output_dict['detection_classes'][0]==3) & (output_dict['detection_scores'][0]>= 0.1):\n",
    "\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin),(box0.xmax,box0.ymax),box0.colour,2)\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin-60),(box0.xmax,box0.ymin),box0.colour,-1)\n",
    "        image = cv2.putText(image, box0.label, (box0.xmin, box0.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box0.ripeness, (box0.xmin, box0.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        \n",
    "    if (output_dict['detection_classes'][0]==1) or (output_dict['detection_classes'][0]==2) & (output_dict['detection_scores'][0]>= 0.1):\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin),(box0.xmax,box0.ymax),box0.colour,2)\n",
    "        image = cv2.rectangle(image,(box0.xmin,box0.ymin-60),(box0.xmax,box0.ymin),box0.colour,-1)\n",
    "        image = cv2.putText(image, box0.label, (box0.xmin, box0.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box0.ripeness, (box0.xmin, box0.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    \n",
    "    \n",
    "# second Box condition for three classes     \n",
    "        \n",
    "    if  (output_dict['detection_classes'][1]==5) & (output_dict['detection_scores'][1]>= 0.4):\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin),(box1.xmax,box1.ymax),box1.colour,2)\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin-60),(box1.xmax,box1.ymin),box1.colour,-1)\n",
    "        image = cv2.putText(image, box1.label, (box1.xmin, box1.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box1.ripeness, (box1.xmin, box1.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        \n",
    "    if  (output_dict['detection_classes'][1]==3) & (output_dict['detection_scores'][1]>= 0.1):\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin),(box1.xmax,box1.ymax),box1.colour,2)\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin-60),(box1.xmax,box1.ymin),box1.colour,-1)\n",
    "        image = cv2.putText(image, box1.label, (box1.xmin, box1.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box1.ripeness, (box1.xmin, box1.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        \n",
    "    if (output_dict['detection_classes'][1]==1) or (output_dict['detection_classes'][1]==2) & (output_dict['detection_scores'][1]>= 0.9):\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin),(box1.xmax,box1.ymax),box1.colour,2)\n",
    "        image = cv2.rectangle(image,(box1.xmin,box1.ymin-60),(box1.xmax,box1.ymin),box1.colour,-1)\n",
    "        image = cv2.putText(image, box1.label, (box1.xmin, box1.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box1.ripeness, (box1.xmin, box1.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "    \n",
    "    \n",
    "#Third Box condition for three classes    \n",
    "    \n",
    "    if  (output_dict['detection_classes'][2]==5) & (output_dict['detection_scores'][2]>= 0.5):\n",
    "\n",
    "        image = cv2.rectangle(image,(box2.xmin,box2.ymin),(box2.xmax,box2.ymax),box2.colour,2)\n",
    "        image = cv2.rectangle(image,(box2.xmin,box2.ymin-60),(box2.xmax,box2.ymin),box2.colour,-1)\n",
    "        image = cv2.putText(image, box2.label, (box2.xmin, box2.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box2.ripeness, (box2.xmin, box2.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        \n",
    "    if  (output_dict['detection_classes'][2]==3) & (output_dict['detection_scores'][2]>= 0.1):\n",
    "        image = cv2.rectangle(image,(box2.xmin,box2.ymin),(box2.xmax,box2.ymax),box2.colour,2)\n",
    "        image = cv2.rectangle(image,(box2.xmin,box2.ymin-60),(box2.xmax,box2.ymin),box2.colour,-1)\n",
    "        image = cv2.putText(image, box2.label, (box2.xmin, box2.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box2.ripeness, (box2.xmin, box2.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)        \n",
    "        \n",
    "    if (output_dict['detection_classes'][2]==1) or (output_dict['detection_classes'][2]==2) & (output_dict['detection_scores'][1]>= 0.9):\n",
    "        image = cv2.rectangle(image,(box2.xmin,box2.ymin),(box2.xmax,box2.ymax),box2.colour,2)\n",
    "        image = cv2.rectangle(image,(box2.xmin,box2.ymin-60),(box2.xmax,box2.ymin),box2.colour,-1)\n",
    "        image = cv2.putText(image, box2.label, (box2.xmin, box2.ymin-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        image = cv2.putText(image, box2.ripeness, (box2.xmin, box2.ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "    \n",
    "    \n",
    "    #saving the processed image frames\n",
    "    if (ret == True):\n",
    "        out.write(image)\n",
    "        cv2.imshow('object detection', cv2.resize(image, (800,600),-1))\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    else:\n",
    "        break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        out.release()\n",
    "#         break\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to be able to view processed video\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
